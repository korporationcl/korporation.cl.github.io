<!DOCTYPE html>
<html lang="en">




<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>
    
    Memory Management in Linux
     | Victor Vargas 
  </title>
  <link rel="stylesheet" href='https://www.korporation.cl/css/site.min.eb4797a608f467160f71b5cc518dffb9b3fef0edc95e6def8dc4033ba1888b8f414e3d1d3e6c9804ca3e6f125539d8af48b28dcecb4eafc5805bde0b3c8d6956.css' integrity='sha512-60eXpgj0ZxYPcbXMUY3/ubP&#43;8O3JXm3vjcQDO6GIi49BTj0dPmyYBMo&#43;bxJVOdivSLKNzstOr8WAW94LPI1pVg=='>
  <link rel="canonical" href="https://www.korporation.cl/posts/memory-management-in-linux/">
  <link rel="alternate" type="application/rss&#43;xml" href="https://www.korporation.cl/index.xml" title="korporation">
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">
<meta name="author" content="Victor Vargas">
<meta name="description" content="Introduction I hope this introduction serves well for anyone who needs a refresher about Operating systems in general, or people who wants to know how a Linux/Unix system works under the hood, after all the Cloud is made of Unix/Linux systems (huge part of it). Memory management is a complex subject, and I declared myself a rookie in the sense about how the Linux kernel works, however I will try to include as much details as I can possible explain or understand.">

<meta property="og:title" content="Memory Management in Linux" />
<meta property="og:description" content="Introduction I hope this introduction serves well for anyone who needs a refresher about Operating systems in general, or people who wants to know how a Linux/Unix system works under the hood, after all the Cloud is made of Unix/Linux systems (huge part of it). Memory management is a complex subject, and I declared myself a rookie in the sense about how the Linux kernel works, however I will try to include as much details as I can possible explain or understand." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.korporation.cl/posts/memory-management-in-linux/" />
<meta property="article:published_time" content="2020-01-02T17:20:51+01:00" />
<meta property="article:modified_time" content="2020-01-31T02:02:49+01:00" />


</head>
<body><nav class="navbar is-transparent " role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a class="navbar-item" href="https://www.korporation.cl/">
      <figure class="image">
        <img alt="" class="is-rounded" src="https://www.gravatar.com/avatar/830a5d3d6a048f8ca89338f0d4f66493?s=128&d=identicon">
      </figure>
    </a>
    <a class="navbar-item" href="https://www.korporation.cl/">
      korporation
    </a>
  </div>
  
  <div class="navbar-menu">
    <div class="navbar-start">
      
      <a class="navbar-item" href="https://www.korporation.cl/tags/cloud-computing/">
        
        Cloud computing
        
      </a>
      
      <a class="navbar-item" href="https://www.korporation.cl/tags/computer-science/">
        
        Computer science
        
      </a>
      
      <a class="navbar-item" href="https://www.korporation.cl/tags/kernel/">
        
        Kernel
        
      </a>
      
      <a class="navbar-item" href="https://www.korporation.cl/tags/linux/">
        
        Linux
        
      </a>
      
      <a class="navbar-item" href="https://www.korporation.cl/tags/memory-management/">
        
        Memory management
        
      </a>
      
    </div>
    
    <div class="navbar-end">
      
      <a class="navbar-item" href="https://github.com/korporationcl/" rel="noopener" target="_blank">
        <span class="icon">
          <img alt="github-circle" src='https://www.korporation.cl/icons/svg/github-circle.svg'>
        </span>
      </a>
      
      <a class="navbar-item" href="https://www.linkedin.com/in/victorvargasb/" rel="noopener" target="_blank">
        <span class="icon">
          <img alt="linkedin" src='https://www.korporation.cl/icons/svg/linkedin.svg'>
        </span>
      </a>
      
      <a class="navbar-item" href="mailto:victor@korporation.cl" target="_blank">
        <span class="icon">
          <img alt="email" src='https://www.korporation.cl/icons/svg/email.svg'>
        </span>
      </a>
      <a class="navbar-item" href="https://www.korporation.cl/index.xml" target="_blank">
        <span class="icon">
          <img alt="rss" src='https://www.korporation.cl/icons/svg/rss.svg'>
        </span>
      </a>
      
    </div>
  </div>
</nav>
<section class="hero is-small is-info is-fullwidth">
  <div class="hero-body">
<div class="container">
  <h1 class="title">
    Memory Management in Linux
  </h1>
  <h2 class="subtitle">
    <time datetime='2020-01-02T17:20:51&#43;01:00'>
      Posted: January 02, 2020
    </time>
    Last update: 31/01/2020

    
    <br>
    
    
    
    <a class="tag is-link" href="https://www.korporation.cl/tags/linux/">linux</a>
    
    
    
    
    <a class="tag is-link" href="https://www.korporation.cl/tags/kernel/">kernel</a>
    
    
    
    
    <a class="tag is-link" href="https://www.korporation.cl/tags/memory-management/">memory management</a>
    
    
    
    
    <a class="tag is-link" href="https://www.korporation.cl/tags/cloud-computing/">cloud computing</a>
    
    
    
    
    <a class="tag is-link" href="https://www.korporation.cl/tags/computer-science/">computer science</a>
    
    
    
  </h2>
</div>

  </div>
</section>
<section class="section">
  <div class="container">
<div class="content is-medium">
  <h1 id="introduction">Introduction</h1>
<p>I hope this introduction serves well for anyone who needs a refresher about Operating systems in general, or people who wants to know how a Linux/Unix system works under the hood, after all the Cloud is made of Unix/Linux systems (huge part of it). Memory management is a complex subject, and I declared myself a rookie in the sense about how the Linux kernel works, however I will try to include as much details as I can possible explain or understand.</p>
<p>Take a deep breath because it&rsquo;s going to be a long ride</p>
<hr>
<h1 id="why-do-we-even-need-memory">Why do we even need memory?</h1>
<p>On brendan&rsquo;s book[2], the introduction to Chapter 7 says:</p>
<blockquote>
<p>System main memory stores application and kernel instructions, their working data, and file system caches. In many systems, the secondary storage for this data is the primary storage devices (disks), which operate orders of magnitude mode slowly.</p>
</blockquote>
<p>But this doesn&rsquo;t actually give you the answer.. the actual reason is because the <code>CPU</code> needs to execute a set of instructions which are copied from a storage device (hard drive) to the main memory aka <code>RAM</code> and here the <code>fetch-decode-execute</code>cycle shows up. If you want to learn more about it watch this <a href="https://www.youtube.com/watch?v=jFDMZpkUWCw">video</a> and follow-up with this <a href="https://www.bbc.co.uk/bitesize/guides/z2342hv/revision/5">article</a>. At this point you know why memory is needed. Before introducing the next topic I would like to quote what Linus[4] wrote on his thesis a while ago, in regards of the memory management process:</p>
<blockquote>
<p>Memory is one of the most fundamental resources in the system, and as such the performance of the memory management layer is critical to the system. Making memory management efficient is thus of primary importance: not only do the routines have to be fast, they have to be clever too, sharing physical pages aggressively in order to get the most out of a system.</p>
</blockquote>
<p>furthermore&hellip;</p>
<blockquote>
<p>However, to make matters even worse, memory management is typically one of the areas where there are absolutely no hardware standards, and different CPU’s use very different means of mapping virtual addresses into physical memory pages. As such, memory management is one area where traditionally most of the code has been very architecture-dependent, and only very little high-level code has been shared across architectures even though we would like to share a lot more.</p>
</blockquote>
<p>As a reminder, back in the 90&rsquo;s, Linus starting working on the kernel on the <strong>Intel-80386</strong>:</p>
<blockquote>
<p>The original Linux was not only extremely PC-centric, it wallowed in features available on PC’s and was totally unconcerned with most portability issues other than at a user level. The original Intel 80386 architecture that Linux was written for is perhaps the example of current CISC design, and has high-level support for features other current CPU’s would not even dream about implementing (see for example [CG87]).</p>
</blockquote>
<p>Linus mentioned on his thesis that everything related to <code>memory management</code> belongs under the directory <a href="https://github.com/torvalds/linux/tree/master/mm">mm/</a>, as so:</p>
<blockquote>
<p>The basic Linux kernel is directly organized around the primary services it provides: process handling, memory management, file system management, network access and the drivers for the hardware. These areas correspond to the kernel source directories kernel, mm, fs, net and drivers respectively.</p>
</blockquote>
<p>but also, in The magic Garden explained[3], Chapter 3, it&rsquo;s been stated that:</p>
<blockquote>
<p>A major concern for any operating system is the method by which it manages a process given the restrictions imposed by the amount of physical memory installed in the computer hardware. It must be determined where the process will be placed in main memory, and how memory is allocated to it as it grows and shrinks during its execution. One problem that is familiar to <strong>all</strong> operating systems is what do when memory is <strong>scarce</strong>.</p>
</blockquote>
<blockquote>
<p>To overcome these and other memory management problems, UNIX System V Release 4 has adopted a concept of <strong>virtual memory</strong> (Moran 1988).</p>
</blockquote>
<hr>
<h2 id="physical-memory">Physical Memory</h2>
<p>Physical memory is what we know as the <strong>RAM</strong> (Random Access Memory), and is found on the memory bank of your laptop or more commonly servers (if you are running infrastructure on the cloud same principle applies). Most of servers out there are NUMA (Non-Uniform memory access) but UMA used to be the rule. The main difference in UMA there is a single shared BUS that connects the memory controller with the CPU and the other components. Whereas in NUMA, each CPU has its own internal connection with the memory controller. To easily understand the difference see the following diagram:</p>
<p><img src="https://3l4sbp4ao2771ln0f54chhvm-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/NUMA-Architecture.png" alt="numa vs uma"></p>
<p>Each memory bank is the kernel is known as a <strong>Node</strong> (in my case <code>node0</code>). In NUMA systems, and each processor can access a different node, which is known as the <strong>distance</strong> (this has a cost associated in terms of latency, since accessing the CPUs local node is faster than a remote node). Nodes are known inside the kernel as <code>type pg_data_t</code>.</p>
<p>A node is divided in different <strong>Zones</strong> which represent different ranges of memory. On the <code>x86</code> the zones are:</p>
<ul>
<li>ZONE_DMA (first 16MB)</li>
<li>ZONE_NORMAL (Between 16MB and 896MB, this is where many kernel operations happen and is the most critical zone)</li>
<li>ZONE_HIGHMEM (Between 896MB - END)</li>
</ul>
<p><strong>Zones</strong> are declared in the <a href="https://github.com/torvalds/linux/blob/master/include/linux/mmzone.h">include/linux/mmzone.h</a> file, they as declared as <code>struct zone</code>. checking my laptop I noticed the following:</p>
<pre><code class="language-lang=bash" data-lang="lang=bash">$ cat /proc/pagetypeinfo
Page block order: 9
Pages per block:  512

Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10 
Node    0, zone      DMA, type    Unmovable      1      1      1      0      2      1      1      0      1      0      0 
Node    0, zone      DMA, type      Movable      0      0      0      0      0      0      0      0      0      1      3 
Node    0, zone      DMA, type  Reclaimable      0      0      0      0      0      0      0      0      0      0      0 
Node    0, zone      DMA, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0 
Node    0, zone      DMA, type          CMA      0      0      0      0      0      0      0      0      0      0      0 
Node    0, zone      DMA, type      Isolate      0      0      0      0      0      0      0      0      0      0      0 
Node    0, zone    DMA32, type    Unmovable    838    384     65     16      9      2      0      0      0      0      0 
Node    0, zone    DMA32, type      Movable  26195  10502    648    146     20      4      0      1      0      0      0 
Node    0, zone    DMA32, type  Reclaimable    506    657    590    404    188     82     20     13      2      1      0 
Node    0, zone    DMA32, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0 
Node    0, zone    DMA32, type          CMA      0      0      0      0      0      0      0      0      0      0      0 
Node    0, zone    DMA32, type      Isolate      0      0      0      0      0      0      0      0      0      0      0 
Node    0, zone   Normal, type    Unmovable    440    357    227     72     38      6      0      0      0      0      0 
Node    0, zone   Normal, type      Movable  11803   2752    730     78     15     11      3      2      2      0      0 
Node    0, zone   Normal, type  Reclaimable      0     38     33     16      1      0      0      0      0      0      0 
Node    0, zone   Normal, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0 
Node    0, zone   Normal, type          CMA      0      0      0      0      0      0      0      0      0      0      0 
Node    0, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0 

Number of blocks type     Unmovable      Movable  Reclaimable   HighAtomic          CMA      Isolate 
Node 0, zone      DMA            1            7            0            0            0            0 
Node 0, zone    DMA32           25         1359          144            0            0            0 
Node 0, zone   Normal          122         2039          155            0            0            0 
</code></pre><p><code>DMA32</code> zone only exists under <code>x86_64</code> systems,  the <code>ZONE_HIGHMEM</code> is created only in 32 bits too.  The complete answer is found on the same source code actually:</p>
<pre><code class="language-lang=c" data-lang="lang=c">enum zone_type {
	/*
	 * ZONE_DMA and ZONE_DMA32 are used when there are peripherals not able
	 * to DMA to all of the addressable memory (ZONE_NORMAL).
	 * On architectures where this area covers the whole 32 bit address
	 * space ZONE_DMA32 is used. ZONE_DMA is left for the ones with smaller
	 * DMA addressing constraints. This distinction is important as a 32bit
	 * DMA mask is assumed when ZONE_DMA32 is defined. Some 64-bit
	 * platforms may need both zones as they support peripherals with
	 * different DMA addressing limitations.
	 *
	 * Some examples:
	 *
	 *  - i386 and x86_64 have a fixed 16M ZONE_DMA and ZONE_DMA32 for the
	 *    rest of the lower 4G.
	 *
	 *  - arm only uses ZONE_DMA, the size, up to 4G, may vary depending on
	 *    the specific device.
	 *
	 *  - arm64 has a fixed 1G ZONE_DMA and ZONE_DMA32 for the rest of the
	 *    lower 4G.
	 *
	 *  - powerpc only uses ZONE_DMA, the size, up to 2G, may vary
	 *    depending on the specific device.
	 *
	 *  - s390 uses ZONE_DMA fixed to the lower 2G.
	 *
	 *  - ia64 and riscv only use ZONE_DMA32.
	 *
	 *  - parisc uses neither.
	 */

...
#ifdef CONFIG_HIGHMEM
	/*
	 * A memory area that is only addressable by the kernel through
	 * mapping portions into its own address space. This is for example
	 * used by i386 to allow the kernel to address the memory beyond
	 * 900MB. The kernel will set up special mappings (page
	 * table entries on i386) for each page that the kernel needs to
	 * access.
	 */
</code></pre><p>Each physical page in the system has a <code>page struct</code>, which is declared in the <a href="https://github.com/torvalds/linux/blob/master/include/linux/mm_types.h">include/linux/mm_types.h</a> file and is probably the most important structure in regards of memory management.</p>
<h2 id="virtual-memory">Virtual Memory</h2>
<p>Brendan&rsquo;s book mentioned this briefly, and after getting that reference from <a href="https://dl.acm.org/doi/10.1145/234313.234403">Peter J. Denning</a>:</p>
<blockquote>
<p>The designers of the Atlas computer at the University of Manchester invented virtual memory in the <code>1950s</code> to eliminate a looming programming problem: <strong>planning</strong> and <strong>scheduling data</strong> transfers between main and secondary memory and <strong>recompiling</strong> programs for each change of <strong>size</strong> of main memory.</p>
</blockquote>
<p>Imagine you were in the 1970s-1980s and processors like the <code>Intel 8080</code> only provided an address space of 64kbytes (you may have in your laptop at least <code>8192000</code> / <code>8GB</code> RAM), but back those days processors used direct physical memory address to access code and data. There is something in particular mentioned in the book, programmers had to arrange that the program code and data avoided any <strong>holes</strong> in the given address space. It is much convenient to ignore the physical layout of a machine&rsquo;s memory and work instead with an idealised or <strong>virtual machine</strong>. A program/process can then reference the virtual memory addresses for both code and data and a <strong>hole</strong> in memory can be <strong>ignored</strong> since the restrictions imposed by physical memory are <strong>invisible</strong> to both the program and programmer.</p>
<blockquote>
<p>A virtual address schema gives the illussion that there is more memory available than is physically installed in the machine. This allows the OS to run a program that is larger than physical memory, however a program reside in physical memory and it must generate real addresses for both its code and data. Therefore, a <strong>translation</strong> mecanism is needed to convert virtual memory to physical memory addresses at run time and must not provide any significant overhead.</p>
</blockquote>
<p>From the previous quote, it is referring to the Memory Management Unit / <strong>MMU</strong>. <a href="https://en.wikipedia.org/wiki/Translation_lookaside_buffer">Translation Lookaside Buffer</a> or <strong>TLB</strong>, is a memory cache use to reduce the time taken to access a memory location and it stores the recent translations of virtual memory to physical memory.</p>
<p>A process address space has <strong>its own virtual address space</strong>, which of course is mapped to physical memory by the operating system (main memory and swap, if exists). Another important definition to remember is a <code>page</code>. A page is a unit of memory, historically has been <code>4kb</code> or <code>8kb</code> but depends of the architecture, and its how the physical memory has been divided (also known as <code>page frames</code>). The selection of the size is defined when the kernel is built. On the latest Ubuntu <code>19.10</code> release the page size is still set to <code>4k</code>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">$root@testing:~# uname -r
5.3.0-26-generic

$root@testing:~# getconf PAGE_SIZE
<span style="color:#ae81ff">4096</span>
</code></pre></div><p>For now, consider the following example (From the awesome <a href="https://os.phil-opp.com/">&ldquo;Writing an OS in Rust&rdquo;</a>), running the same process twice in parallel:</p>
<p><img src="https://os.phil-opp.com/paging-introduction/segmentation-same-program-twice.svg" alt="allocating virtual memory"></p>
<blockquote>
<p>Here the same program runs twice, but with different translation functions. The first instance has an segment offset of 100, so that its virtual addresses 0–150 are translated to the physical addresses 100–250. The second instance has offset 300, which translates its virtual addresses 0–150 to physical addresses 300–450. This allows both programs to run the same code and use the same virtual addresses without interfering with each other.</p>
</blockquote>
<p>The virtual address space is implemented and handled in the Memory Management Unit by the processor and its by <strong>process</strong>. The OS needs to fill out the page table data (<strong>by each process</strong>) every time the process is loaded, this is a another feature implemented in the CPU (<code>cr3</code> <a href="https://wiki.osdev.org/CPU_Registers_x86">register</a>). When a process its in CPU, loads the page table data from the highest hierarchy level (multi level pages) aka level 4 (this is also known as <strong>Page Global Directory</strong>, <strong>Page Upper Directory</strong>, <strong>Page Middle Directory</strong> and <strong>Page Table</strong>).</p>
<p>The page table data structure then is composed as:</p>
<p><img src="https://static.lwn.net/images/cpumemory/cpumemory.19-sm.png" alt="page table data structure"></p>
<blockquote>
<p>The virtual address is, in this example, split into at least five parts. Four of these parts are indexes into the various directories. The level 4 directory is referenced using the <code>cr3</code> register in the CPU. The content of the level 4 to level 2 directories is a reference to next lower level directory. If a directory entry is marked empty it obviously need not point to any lower directory. This way the page table tree can be sparse and compact. The entries of the level 1 directory are partial physical addresses, plus auxiliary data like access permissions.</p>
</blockquote>
<blockquote>
<p>The CPU takes the index part of the virtual address corresponding to this directory and uses that index to pick the appropriate entry. This entry is the address of the next directory, which is indexed using the next part of the virtual address. This process continues until it reaches the level 1 directory, at which point the value of the directory entry is the high part of the physical address. The physical address is completed by adding the page offset bits from the virtual address. This process is called <strong>page tree walking</strong>. Some processors (like x86 and x86-64) perform this operation in hardware, others need assistance from the OS.</p>
</blockquote>
<p>Pages are commonly <code>4k</code> size as seen before, and each page table can have up to <code>512</code> entries,  each entry is <code>8b</code> (512 * 8 = 4096bytes or 4k - it fits exactly in one page), page tables are also stored in memory.</p>
<h1 id="segmentation">Segmentation</h1>
<p>One of the main tasks of the operating system is to isolate a process from each other, so in order to achieve this the system uses hardware capability to protect memory areas. The approach differs from hardware and the implementation on the OS. On <code>x86</code>, the two ways to protect memory are <code>segmentation</code> and <code>paging</code>.</p>
<p>The support for segmentation has been removed on <code>x86</code> for <code>64 bits</code> and this concept applies mostly in legacy systems aka <code>32</code> bits.</p>
<h1 id="fragmentation">Fragmentation</h1>
<p>This is more clear after reviewing the following case:</p>
<p><img src="https://os.phil-opp.com/paging-introduction/segmentation-fragmentation.svg" alt="memory fragmentation"></p>
<blockquote>
<p>There is no way to map the third instance of the program to virtual memory without overlapping, even though there is more than enough free memory available. The problem is that we need <code>continuous memory</code> and can&rsquo;t use the small free chunks.
One way to combat this fragmentation is to <strong>pause execution</strong>, move the used parts of the memory closer together, update the translation, and then resume execution:</p>
</blockquote>
<p><img src="https://os.phil-opp.com/paging-introduction/segmentation-fragmentation-compacted.svg" alt="memory fragmentation fixed"></p>
<blockquote>
<p>The disadvantage of this defragmentation process is that is needs to copy large amounts of memory which decreases performance. It also needs to be done regularly before the memory becomes too fragmented. This makes performance unpredictable, since programs are paused at random times and might become unresponsive.
The fragmentation problem is one of the reasons that segmentation is no longer used by most systems. In fact, segmentation is not even supported in 64-bit mode on x86 anymore. Instead paging is used, which completely avoids the fragmentation problem.</p>
</blockquote>
<h1 id="paging">Paging</h1>
<blockquote>
<p>The idea is to divide both the virtual and the physical memory space into small, fixed-size blocks. The blocks of the virtual memory space are called <strong>pages</strong> and the blocks of the physical address space are called <strong>frames (page frames)</strong>. Each page can be individually mapped to a frame, which makes it possible to split larger memory regions across non-continuous physical frames.</p>
</blockquote>
<blockquote>
<p>The advantage of this becomes visible if we recap the example of the fragmented memory space, but use paging instead of segmentation this time:</p>
</blockquote>
<p><img src="https://os.phil-opp.com/paging-introduction/paging-fragmentation.svg" alt="Paging in action"></p>
<blockquote>
<p>In this example we have a page size of 50 bytes, which means that each of our memory regions is split across three pages. Each page is mapped to a frame individually, so a continuous virtual memory region can be mapped to <strong>non-continuous physical frames</strong>. This allows us to start the third instance of the program without performing any defragmentation before.</p>
</blockquote>
<h1 id="references">References</h1>
<ol>
<li><a href="https://www.kernel.org/doc/html/latest/admin-guide/mm/concepts.html#mm-concepts">https://www.kernel.org/doc/html/latest/admin-guide/mm/concepts.html#mm-concepts</a></li>
<li><a href="https://www.amazon.com/Systems-Performance-Enterprise-Brendan-Gregg/dp/0133390098/ref=sr_1_1?keywords=systems+performance&amp;qid=1577983140&amp;s=books&amp;sr=1-1">Systems Performance in the cloud and enterprise</a></li>
<li><a href="https://www.amazon.com/Magic-Garden-Explained-Internals-Release/dp/0130981389">The Magic Garden explained</a></li>
<li><a href="https://www.cs.helsinki.fi/u/kutvonen/index_files/linus.pdf">Linux: A portable operating system by Linus Torvals</a></li>
<li><a href="https://www.thegeekstuff.com/2012/02/linux-memory-management/">https://www.thegeekstuff.com/2012/02/linux-memory-management/</a></li>
<li><a href="https://os.phil-opp.com/paging-introduction/">https://os.phil-opp.com/paging-introduction/</a></li>
<li><a href="https://www.bottomupcs.com/virtual_memory_linux.xhtml">https://www.bottomupcs.com/virtual_memory_linux.xhtml</a></li>
<li><a href="https://lwn.net/Articles/253361/">https://lwn.net/Articles/253361/</a></li>
<li><a href="https://www.kernel.org/doc/gorman/html/understand/understand005.html">https://www.kernel.org/doc/gorman/html/understand/understand005.html</a></li>
</ol>

</div>


  </div>
</section><footer class="footer">
  <div class="content has-text-centered">
    
    
    <p>
      
      <a href="https://github.com/orf/bare-hugo-theme" target="_blank">Bare Hugo theme.</a>
      
      
    </p>
    
  </div>
</footer>


</body>
</html>
